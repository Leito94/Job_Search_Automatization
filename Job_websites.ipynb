{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from selenium import webdriver as wb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "test_search = \"data scientist\"\n",
    "test_ex = \"Senior Data Scientist\"\n",
    "\n",
    "if test_search.lower() in test_ex.lower():\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What are you looking for data scientist\n",
      "Where are you searching? germany\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching on indeed...\n",
      "searching on stepstone...\n",
      "searching on stack overflow...\n",
      "searching on XING...\n"
     ]
    }
   ],
   "source": [
    "class JobFinder:\n",
    "    def __init__(self, search, place):\n",
    "        self.search = search\n",
    "        self.place = place\n",
    "        \n",
    "        # empty list for the job info\n",
    "        self.joblist = []\n",
    "        \n",
    "        # get the user agent list so that I dont get blocked\n",
    "        with open(\"user_agent_list.json\", \"r\") as f:\n",
    "            self.user_agent_list = json.load(f)\n",
    "        \n",
    "    def search_stepstone(self):\n",
    "        \n",
    "        print(\"searching on stepstone...\")\n",
    "        # modify stepstone url\n",
    "        stepstone_search = self.search.replace(\" \", \"%20\")\n",
    "        stepstone_place = self.place.replace(\" \", \"%20\")\n",
    "        \n",
    "        # steptstone url\n",
    "        stepstone_url = \"https://www.stepstone.de/5/ergebnisliste.html?stf=freeText&ns=1&companyid=0&sourceofthesearchfield=resultlistpage%3Ageneral&qs=[]&cityid=0&ke={}&ws={}&radius=30&suid=e4f10731-b7c4-4e30-a419-08dcd96f8eed&ob=date&of={}\"\n",
    "        # list for the pages\n",
    "        stepstone_page_list = range(0, 200, 25)\n",
    "\n",
    "        for page in stepstone_page_list:\n",
    "            \n",
    "            # get random user agent\n",
    "            headers = {\"User-Agent\" :random.choice(self.user_agent_list)}\n",
    "            try:\n",
    "                r = requests.get(stepstone_url.format(stepstone_search, stepstone_place, page), headers = headers)\n",
    "                soup = bs(r.content, \"lxml\")\n",
    "                \n",
    "                body = soup.find(\"div\", class_ = \"ResultsSectionContainer-gdhf14-0 gvBCse\")\n",
    "                divs = body.find_all(\"div\", class_ = \"sc-fzXfOu\")\n",
    "                \n",
    "                for div in divs:\n",
    "                    try:\n",
    "                        title = div.find(\"div\", class_ = \"sc-fzXfOw\").text\n",
    "                        if self.search.lower() not in title.lower():\n",
    "                            continue\n",
    "                    except:\n",
    "                        title = \"\"\n",
    "                    try:\n",
    "                        company = div.find(\"div\", {\"data-at\" : \"job-item-company-name\"}).text\n",
    "                    except:\n",
    "                        company = \"\"\n",
    "                    try:\n",
    "                        city = div.find(\"li\", {\"data-at\" : \"job-item-location\"}).text\n",
    "                    except:\n",
    "                        city = \"\"\n",
    "                    try: \n",
    "                        summary = div.find(\"a\", {\"data-offer-meta-text-snippet-link\" : \"true\"}).text\n",
    "                    except:\n",
    "                        summary = \"\"\n",
    "                    try:\n",
    "                        time = div.find(\"time\").text\n",
    "                        try:\n",
    "                            number, unit = div.find(\"time\").text.split()[1:3]\n",
    "                            number = int(number)\n",
    "                            if unit == \"Stunde\" or unit == \"Stunden\":\n",
    "                                time = round(number/24, 2)\n",
    "                            elif unit == \"Tag\" or unit == \"Tagen\":\n",
    "                                time = number\n",
    "                            elif unit == \"Woche\" or unit == \"Wochen\":\n",
    "                                time = number * 7    \n",
    "                        except:\n",
    "                            pass\n",
    "                    except:\n",
    "                        time = None\n",
    "                    \n",
    "                    source = \"stepstone\"\n",
    "\n",
    "                    job = {\n",
    "                                \"title\" : title,\n",
    "                                \"company\" : company,\n",
    "                                \"city\" : city,\n",
    "                                \"time\" : time,\n",
    "                                \"summary\" : summary,\n",
    "                                \"source\" : source,\n",
    "                                \"link\" : stepstone_url.format(stepstone_search, stepstone_place, page)\n",
    "                            }\n",
    "\n",
    "                    self.joblist.append(job)\n",
    "                    \n",
    "            except:\n",
    "                print(\"no data found on page \" + str(page))\n",
    "            \n",
    "        try:\n",
    "            df = pd.DataFrame(self.joblist)\n",
    "            return df\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def search_indeed(self):\n",
    "        \n",
    "        print(\"searching on indeed...\")\n",
    "        # how many pages do we want to scrape?\n",
    "        indeed_page_list = range(0, 100, 10) # scrape first 10 pages\n",
    "        \n",
    "        # modify indeed url\n",
    "        indeed_search = self.search.replace(\" \", \"+\")\n",
    "        indeed_place = self.place.replace(\" \", \"+\")\n",
    "        \n",
    "        # indeed url\n",
    "        indeed_url = \"https://de.indeed.com/jobs?q={}&l={}&sort=date&start={}\"\n",
    "\n",
    "        for page in indeed_page_list:\n",
    "\n",
    "            # get random user agent\n",
    "            headers = {\"User-Agent\" :random.choice(self.user_agent_list)}\n",
    "            try:\n",
    "                \n",
    "                r = requests.get(indeed_url.format(indeed_search, indeed_place, page), headers = headers)\n",
    "                # check if we can access the website\n",
    "\n",
    "                soup = bs(r.content, \"lxml\")\n",
    "                divs = soup.find_all(\"div\", class_ = \"jobsearch-SerpJobCard\")\n",
    "            \n",
    "\n",
    "                for div in divs:\n",
    "                    try:\n",
    "                        title = div.find(\"a\").text.strip()\n",
    "                        if self.search.lower() not in title.lower():\n",
    "                            continue\n",
    "                    except:\n",
    "                        title = \"\"\n",
    "                    try:\n",
    "                        company = div.find(\"span\", class_ = \"company\").text.strip()\n",
    "                    except:\n",
    "                        company = \"\"\n",
    "                    try:\n",
    "                        city = div.find(\"span\", class_ = \"location accessible-contrast-color-location\").text.strip()\n",
    "                    except:\n",
    "                        city = \"\"\n",
    "                    try:\n",
    "                        summary = div.find(\"div\", {\"class\" : \"summary\"}).text.strip().replace(\"\\n\",\"\")\n",
    "                    except:\n",
    "                        summary = \"\"\n",
    "                    try:\n",
    "                        time = div.find(\"span\", {\"class\" : \"date\"}).text\n",
    "                        try:\n",
    "                            unit = time.split()[0]\n",
    "                            if unit == \"Gerade\":\n",
    "                                time = 0\n",
    "                            elif unit == \"Heute\":\n",
    "                                time = 0.5\n",
    "                            else:\n",
    "                                number = int(time.split()[1])\n",
    "                                time = number\n",
    "                        except:\n",
    "                            pass\n",
    "                           \n",
    "                    except:\n",
    "                        time = None\n",
    "                    source = \"indeed\"\n",
    "\n",
    "                    job = {\n",
    "                                \"title\" : title,\n",
    "                                \"company\" : company,\n",
    "                                \"city\" : city,\n",
    "                                \"time\" : time,\n",
    "                                \"summary\" : summary,\n",
    "                                \"source\" : source,\n",
    "                                \"link\" : indeed_url.format(indeed_search, indeed_place, page)\n",
    "                            }\n",
    "\n",
    "                    self.joblist.append(job)\n",
    "            except:\n",
    "                print(\"no data found on page \" + str(page))\n",
    "            \n",
    "        try:\n",
    "            df = pd.DataFrame(self.joblist)\n",
    "            return df\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def search_stack_overflow(self):\n",
    "        \n",
    "        print(\"searching on stack overflow...\")\n",
    "        \n",
    "        # list for the pages\n",
    "        stack_overflow_page_list = range(0, 5)\n",
    "        # stack overflow url\n",
    "        stack_overflow_url = \"https://stackoverflow.com/jobs?d=20&l={}&q={}&u=Km&pg={}\"\n",
    "        \n",
    "        # modify stack_overflow url\n",
    "        stack_overflow_search = self.search.replace(\" \", \"+\")\n",
    "        stack_overflow_place = self.place.replace(\" \", \"+\")\n",
    "        \n",
    "        for page in stack_overflow_page_list:\n",
    "            # get random user agent\n",
    "            headers = {\"User-Agent\" :random.choice(self.user_agent_list)}\n",
    "            try:\n",
    "                r = requests.get(stack_overflow_url.format(stack_overflow_place, stack_overflow_search, page), headers = headers)\n",
    "                soup = bs(r.content, \"lxml\")\n",
    "\n",
    "                # list of the jobs\n",
    "                body = soup.find(\"div\", class_ = \"listResults\")\n",
    "                jobs = body.find_all(\"div\", {\"class\" : \"-job\"})\n",
    "           \n",
    "\n",
    "                for job in jobs:\n",
    "                    try:\n",
    "                        title = job.find(\"a\", {\"class\" : \"s-link stretched-link\"}).text\n",
    "                        if self.search.lower() not in title.lower():\n",
    "                            continue\n",
    "                    except:\n",
    "                        title = \"\"\n",
    "                    try:    \n",
    "                        company = job.find(\"h3\", {\"class\" : \"fc-black-700 fs-body1 mb4\"}).find(\"span\").text.strip()\n",
    "                    except:\n",
    "                        company = \"\"\n",
    "                    try:\n",
    "                        city = job.find(\"h3\", {\"class\" : \"fc-black-700 fs-body1 mb4\"}).find(\"span\", {\"class\" : \"fc-black-500\"}).text.strip()\n",
    "                    except:\n",
    "                        city = \"\"\n",
    "                    try:\n",
    "                        time = int(job.find(\"ul\", {\"class\" : \"mt4\"}).li.span.text.split(\"d\")[0])\n",
    "                    except:\n",
    "                        time = None\n",
    "                    summary = \"\"\n",
    "                    source = \"stack overflow\"\n",
    "\n",
    "                    job = {\n",
    "                                \"title\" : title,\n",
    "                                \"company\" : company,\n",
    "                                \"city\" : city,\n",
    "                                \"time\" : time,\n",
    "                                \"summary\" : summary,\n",
    "                                \"source\" : source,\n",
    "                                \"link\" : stack_overflow_url.format(stack_overflow_place, stack_overflow_search, page)\n",
    "                            }\n",
    "\n",
    "                    self.joblist.append(job)\n",
    "            \n",
    "            except:\n",
    "                print(\"no data found on page \" + str(page))\n",
    "        try:\n",
    "            df = pd.DataFrame(self.joblist)\n",
    "            return df\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def search_xing(self):\n",
    "        \n",
    "        print(\"searching on XING...\")\n",
    "        \n",
    "        xing_page_list = range(1, 5)\n",
    "\n",
    "        # xing url\n",
    "        xing_url = \"https://www.xing.com/jobs/search?page={}&utf8=%E2%9C%93&nrs=1&keywords={}&location={}&radius=&sort=date\"\n",
    "        chromedriver = r\"C:/Users/Leonhard/Downloads/chromedriver_win32/chromedriver.exe\"\n",
    "        \n",
    "        # for xing url\n",
    "        xing_search = self.search.replace(\" \", \"%20\")\n",
    "        xing_place = self.place.replace(\" \", \"%20\")\n",
    "        \n",
    "        # I dont want chrome to open\n",
    "        options = wb.ChromeOptions()\n",
    "        options.add_argument(\"headless\")\n",
    "        # add user agent\n",
    "        headers = random.choice(self.user_agent_list)\n",
    "        options.add_argument(f\"user-agent:{headers}\")\n",
    "        \n",
    "        for page in xing_page_list:\n",
    "            try:\n",
    "                # need to use selenium\n",
    "                webD = wb.Chrome(chromedriver, options=options)\n",
    "                webD.get(xing_url.format(page, xing_search, xing_place))\n",
    "                soup = bs(webD.page_source, \"lxml\")\n",
    "                body = soup.body\n",
    "                job_list = body.find(\"div\", {\"class\" : \"result-list-result-list-container-8d38ca5b\"})\n",
    "                jobs = job_list.find_all(\"div\", {\"class\" : \"result-result-container-6e907078\"})\n",
    "                \n",
    "                infos = [job.a for job in jobs]\n",
    "                for info in infos:\n",
    "                    try:\n",
    "                        title = info.find(\"h2\").text.strip()\n",
    "                        if self.search.lower() not in title.lower():\n",
    "                            continue\n",
    "                    except:\n",
    "                        title = \"\"\n",
    "                    try:\n",
    "                        company = info.find(\"div\", {\"class\" : \"result-result-subtitle-99125938\"}).text.strip().split(\",\")[0]\n",
    "                    except:\n",
    "                        company = \"\"\n",
    "                    try:\n",
    "                        city = info.find(\"div\", {\"class\" : \"result-result-subtitle-99125938\"}).text.strip().split(\",\")[1]\n",
    "                    except:\n",
    "                        city = \"\"\n",
    "                    try:\n",
    "                        time = info.time.text.strip()\n",
    "                        try:\n",
    "                            time_components = time.split()\n",
    "                            value = int(time_components[0])\n",
    "                            unit = time_components[1]\n",
    "                            if unit == \"minutes\" or unit == \"minute\":\n",
    "                                time = round(value / 1440, 2)\n",
    "                            elif unit == \"hour\" or unit == \"hours\":\n",
    "                                time = round(value / 24, 2)\n",
    "                            elif unit == \"day\" or unit == \"days\":\n",
    "                                time = value\n",
    "                        except:\n",
    "                            pass\n",
    "                    except:\n",
    "                        time = None\n",
    "                    try:\n",
    "                        summary = info.find(\"div\", {\"class\" : \"result-result-description-c7581001\"}).text.strip()\n",
    "                    except:\n",
    "                        summary = \"\"\n",
    "                        \n",
    "                    source = \"XING\"\n",
    "\n",
    "                    job = {\n",
    "                                \"title\" : title,\n",
    "                                \"company\" : company,\n",
    "                                \"city\" : city,\n",
    "                                \"time\" : time,\n",
    "                                \"summary\" : summary,\n",
    "                                \"source\" : source,\n",
    "                                \"link\" : xing_url.format(page, xing_search, xing_place)\n",
    "                            }\n",
    "                    self.joblist.append(job)\n",
    "            \n",
    "            except:\n",
    "                print(\"no data found on page \" + str(page))\n",
    "        try:\n",
    "            df = pd.DataFrame(self.joblist)\n",
    "            return df\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def search_linkedin(self):\n",
    "        \n",
    "        print(\"Searching on LinkedIn...\")\n",
    "        \n",
    "        # list for the pages\n",
    "        linkedin_page_list = range(0, 100, 25)\n",
    "\n",
    "        linkedin_url = \"https://www.linkedin.com/jobs/search/?geoId=103035651&keywords={}&location={}&sortBy=DD&start={}\"\n",
    "        \n",
    "        # to modify url\n",
    "        linkedin_search = self.search.replace(\" \", \"%20\")\n",
    "        linkedin_place = self.place.replace(\" \", \"%20\")\n",
    "        \n",
    "        for page in linkedin_page_list:\n",
    "            try:\n",
    "                headers = {\"User-Agent\" : random.choice(self.user_agent_list)}\n",
    "                r = requests.get(linkedin_url.format(linkedin_search, linkedin_place, page), headers = headers)\n",
    "                soup = bs(r.content, \"lxml\")\n",
    "                job_list = soup.find(\"section\", {\"class\" : \"results__list\"}).find(\"ul\")\n",
    "\n",
    "                for job in job_list:\n",
    "                    try:\n",
    "                        title = job.a.span.text.strip()\n",
    "                        if self.search.lower() not in title.lower():\n",
    "                            continue\n",
    "                    except:\n",
    "                        title = \"\"\n",
    "                    try:\n",
    "                        company = job.find(\"h4\").text.strip()\n",
    "                    except:\n",
    "                        company = \"\"\n",
    "                    try:\n",
    "                        city = job.find(\"span\", {\"class\" : \"job-result-card__location\"}).text.strip()\n",
    "                    except:\n",
    "                        city = \"\"\n",
    "                    try:\n",
    "                        time = job.find(\"time\").text\n",
    "                        try:\n",
    "                            time_components = time.split()\n",
    "                            value = int(time_components[0])\n",
    "                            unit = time_components[1]\n",
    "                            if unit == \"minutes\" or unit == \"minute\":\n",
    "                                time = round(value / 1440, 2)\n",
    "                            elif unit == \"hour\" or unit == \"hours\":\n",
    "                                time = round(value / 24, 2)\n",
    "                            elif unit == \"day\" or unit == \"days\":\n",
    "                                time = value\n",
    "                        except:\n",
    "                            pass\n",
    "                    except:\n",
    "                        time = None\n",
    "                        \n",
    "                    summary = \"\"\n",
    "                    source = \"LinkedIn\"\n",
    "                 \n",
    "                    job = {\n",
    "                                \"title\" : title,\n",
    "                                \"company\" : company,\n",
    "                                \"city\" : city,\n",
    "                                \"time\" : time,\n",
    "                                \"summary\" : summary,\n",
    "                                \"source\" : source,\n",
    "                                \"link\" : linkedin_url.format(linkedin_search, linkedin_place, page)\n",
    "                            }\n",
    "\n",
    "                    self.joblist.append(job)\n",
    "                    \n",
    "            except:\n",
    "                print(\"no data found on page \" + str(page))\n",
    "        try:\n",
    "            df = pd.DataFrame(self.joblist)\n",
    "            return df\n",
    "        except:\n",
    "            return None\n",
    "                \n",
    "                \n",
    "                \n",
    "    def search_all(self):\n",
    "        \n",
    "        self.search_indeed()\n",
    "        self.search_stepstone()\n",
    "        self.search_stack_overflow()\n",
    "        self.search_xing()\n",
    "        self.search_linkedin()\n",
    "        \n",
    "        df = pd.DataFrame(self.joblist)\n",
    "        \n",
    "        print(\"Joblist is ready!\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "search = input(\"What are you looking for\")\n",
    "place = input(\"Where are you searching?\")\n",
    "\n",
    "#search = \"Data Analyst\"\n",
    "#place = \"Berlin\"\n",
    "\n",
    "today = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "jobs = JobFinder(search, place)\n",
    "df = jobs.search_all()\n",
    "\n",
    "try:\n",
    "    df = df.sort_values(by = \"time\")\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df.to_excel(f\"{today}_job_{search}_in_{place}.xlsx\", index = False)\n",
    "except:\n",
    "    \n",
    "    df.to_excel(f\"{today}_job_{search}_in_{place}.xlsx\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Data Analyst (m/w/d) in Berlin (Betriebswirt/i...</td>\n",
       "      <td>BANKPOWER GmbH Personaldienstleistungen</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>0.21</td>\n",
       "      <td></td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?geoId=10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Data Analyst (m/w/d) in Berlin (Betriebswirt/i...</td>\n",
       "      <td>BANKPOWER GmbH Personaldienstleistungen</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>0.21</td>\n",
       "      <td></td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?geoId=10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Data Analyst (m/w/d) in Berlin (Betriebswirt/i...</td>\n",
       "      <td>BANKPOWER GmbH Personaldienstleistungen</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>0.21</td>\n",
       "      <td></td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?geoId=10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Business Analyst / Data Analyst (m/w/d) Marketing</td>\n",
       "      <td>VPV Versicherungen</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Entwicklung von (fachlichen) Data-Mining-Model...</td>\n",
       "      <td>stepstone</td>\n",
       "      <td>https://www.stepstone.de/5/ergebnisliste.html?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(Senior) Solution &amp; Data Analyst (m/w/d)</td>\n",
       "      <td>Campusjäger GmbH</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>0.38</td>\n",
       "      <td></td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?geoId=10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Data Analyst in Köln und/oder remote</td>\n",
       "      <td>Studitemps</td>\n",
       "      <td>Cologne, Germany</td>\n",
       "      <td>13.00</td>\n",
       "      <td></td>\n",
       "      <td>stack overflow</td>\n",
       "      <td>https://stackoverflow.com/jobs?d=20&amp;l=deutschl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Big Data Analyst / Data Scientist</td>\n",
       "      <td>umlaut</td>\n",
       "      <td>Aachen, Deutschland</td>\n",
       "      <td>19.00</td>\n",
       "      <td></td>\n",
       "      <td>stack overflow</td>\n",
       "      <td>https://stackoverflow.com/jobs?d=20&amp;l=deutschl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Big Data Analyst / Data Scientist</td>\n",
       "      <td>umlaut</td>\n",
       "      <td>Aachen, Deutschland</td>\n",
       "      <td>19.00</td>\n",
       "      <td></td>\n",
       "      <td>stack overflow</td>\n",
       "      <td>https://stackoverflow.com/jobs?d=20&amp;l=deutschl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Web / Data Analyst E-Commerce (m/w/d)</td>\n",
       "      <td>Apologistics GmbH</td>\n",
       "      <td>Markkleeberg, Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>stack overflow</td>\n",
       "      <td>https://stackoverflow.com/jobs?d=20&amp;l=deutschl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Web / Data Analyst E-Commerce (m/w/d)</td>\n",
       "      <td>Apologistics GmbH</td>\n",
       "      <td>Markkleeberg, Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>stack overflow</td>\n",
       "      <td>https://stackoverflow.com/jobs?d=20&amp;l=deutschl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "96   Data Analyst (m/w/d) in Berlin (Betriebswirt/i...   \n",
       "102  Data Analyst (m/w/d) in Berlin (Betriebswirt/i...   \n",
       "108  Data Analyst (m/w/d) in Berlin (Betriebswirt/i...   \n",
       "43   Business Analyst / Data Analyst (m/w/d) Marketing   \n",
       "97            (Senior) Solution & Data Analyst (m/w/d)   \n",
       "..                                                 ...   \n",
       "92                Data Analyst in Köln und/oder remote   \n",
       "93                   Big Data Analyst / Data Scientist   \n",
       "90                   Big Data Analyst / Data Scientist   \n",
       "91               Web / Data Analyst E-Commerce (m/w/d)   \n",
       "94               Web / Data Analyst E-Commerce (m/w/d)   \n",
       "\n",
       "                                     company                       city  \\\n",
       "96   BANKPOWER GmbH Personaldienstleistungen    Berlin, Berlin, Germany   \n",
       "102  BANKPOWER GmbH Personaldienstleistungen    Berlin, Berlin, Germany   \n",
       "108  BANKPOWER GmbH Personaldienstleistungen    Berlin, Berlin, Germany   \n",
       "43                        VPV Versicherungen                  Stuttgart   \n",
       "97                          Campusjäger GmbH    Berlin, Berlin, Germany   \n",
       "..                                       ...                        ...   \n",
       "92                                Studitemps           Cologne, Germany   \n",
       "93                                    umlaut        Aachen, Deutschland   \n",
       "90                                    umlaut        Aachen, Deutschland   \n",
       "91                         Apologistics GmbH  Markkleeberg, Deutschland   \n",
       "94                         Apologistics GmbH  Markkleeberg, Deutschland   \n",
       "\n",
       "      time                                            summary          source  \\\n",
       "96    0.21                                                           LinkedIn   \n",
       "102   0.21                                                           LinkedIn   \n",
       "108   0.21                                                           LinkedIn   \n",
       "43    0.29  Entwicklung von (fachlichen) Data-Mining-Model...       stepstone   \n",
       "97    0.38                                                           LinkedIn   \n",
       "..     ...                                                ...             ...   \n",
       "92   13.00                                                     stack overflow   \n",
       "93   19.00                                                     stack overflow   \n",
       "90   19.00                                                     stack overflow   \n",
       "91     NaN                                                     stack overflow   \n",
       "94     NaN                                                     stack overflow   \n",
       "\n",
       "                                                  link  \n",
       "96   https://www.linkedin.com/jobs/search/?geoId=10...  \n",
       "102  https://www.linkedin.com/jobs/search/?geoId=10...  \n",
       "108  https://www.linkedin.com/jobs/search/?geoId=10...  \n",
       "43   https://www.stepstone.de/5/ergebnisliste.html?...  \n",
       "97   https://www.linkedin.com/jobs/search/?geoId=10...  \n",
       "..                                                 ...  \n",
       "92   https://stackoverflow.com/jobs?d=20&l=deutschl...  \n",
       "93   https://stackoverflow.com/jobs?d=20&l=deutschl...  \n",
       "90   https://stackoverflow.com/jobs?d=20&l=deutschl...  \n",
       "91   https://stackoverflow.com/jobs?d=20&l=deutschl...  \n",
       "94   https://stackoverflow.com/jobs?d=20&l=deutschl...  \n",
       "\n",
       "[119 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
